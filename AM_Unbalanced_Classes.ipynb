{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import seaborn as sns\n",
    "matplotlib.rcParams['savefig.dpi'] = 144"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unbalanced Classes\n",
    "<!-- requirement: images/brain_scan_imbalance.png -->\n",
    "\n",
    "## Introduction: cancer detection case study\n",
    "\n",
    "You are a data scientist at a medical research company and are tasked to build an image classifier that analyzes brain scans. Your goal is to train a machine to recognize brain cancer from the image of a scan. You work hard, engineer clever features, train your model and obtain a 90% accuracy score. At this point you are extremely happy and present your results to the boss. However, she replies your model is terrible. Why is that?\n",
    "\n",
    "One thing you did not notice is that in the dataset you received, 90% of the images come from healthy brains. This means that your sophisticated model is no better than saying that every brain in the dataset is healthy (baseline).\n",
    "\n",
    "This is a typical example of class imbalance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Brain scan imbalance](images/brain_scan_imbalance.png)\n",
    "[](https://en.wikipedia.org/wiki/Radiology#/media/File:Brain_CT_scan.jpg)\n",
    "[](https://en.wikipedia.org/wiki/Brain_tumor#/media/File:Hirnmetastase_MRT-T1_KM.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definition and common scenarios for unbalanced data\n",
    "\n",
    "In a binary classification problem, data is said to be unbalanced if there is a large difference in the number of samples representing each class. This situation is very common, arising each time we are dealing with an anomalous rare event. Besides cancer screening, other examples may include:\n",
    "- **fraud detection**: there are fewer fraudulent than legitimate transactions on a website\n",
    "- **churn prediction**: of the whole customer base, only few customers are churning\n",
    "- **genetic screening**: a specific genetic mutation can be very rare compared to normal\n",
    "- **text categorization**: in a corpus of documents, only a few deal with a specific topic\n",
    "\n",
    "When two classes are balanced, a model predicting only one class for every input will be 50% accurate, i.e. will be correct every other time. As the imbalance increases, a model predicting the majority class will appear to be more and more accurate, which could have serious consequences if not properly diagnosed and handled. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# from https://github.com/glemaitre/UnbalancedDataset\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.datasets import make_classification\n",
    "\n",
    "\n",
    "# Generate some data\n",
    "X, y = make_classification(n_classes=2, class_sep=2, weights=[0.1, 0.9],\n",
    "                           n_informative=3, n_redundant=1, flip_y=0,\n",
    "                           n_features=20, n_clusters_per_class=1,\n",
    "                           n_samples=1000, random_state=10)\n",
    "\n",
    "# Instantiate a PCA object for the sake of easy visualisation\n",
    "pca = PCA(n_components = 2)\n",
    "\n",
    "# Fit and transform x to visualise inside a 2D feature space\n",
    "x_vis = pca.fit_transform(X)\n",
    "\n",
    "# Plot the original data\n",
    "# Plot the two classes\n",
    "palette = sns.color_palette()\n",
    "plt.scatter(x_vis[y==0, 0], x_vis[y==0, 1], label=\"Class #0\", alpha=0.5, \n",
    "            edgecolor='#262626', facecolor=palette[0], linewidth=0.15)\n",
    "plt.scatter(x_vis[y==1, 0], x_vis[y==1, 1], label=\"Class #1\", alpha=0.5, \n",
    "            edgecolor='#262626', facecolor=palette[2], linewidth=0.15)\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "\n",
    "class MajorityPredictor(BaseEstimator, ClassifierMixin):\n",
    "    def __init__(self):\n",
    "        self.majority_class = 0\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        from collections import Counter\n",
    "        self.majority_class = max(Counter(y))\n",
    "        return self\n",
    "    \n",
    "    def predict(self, X):\n",
    "        l = len(X)\n",
    "        return [self.majority_class]*l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mp = MajorityPredictor()\n",
    "mp.fit(X, y)\n",
    "mp.score(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple techniques to deal with unbalanced data\n",
    "\n",
    "There are several techniques to deal with unbalanced classes.\n",
    "\n",
    "### Collect more data\n",
    "Can you collect more samples of the minority class in order to have a better representation of it?\n",
    "This may not be possible in fields like fraud detection, but could potentially happen in the cases of text or image classification.\n",
    "\n",
    "### Use a different performance metric\n",
    "Accuracy is only one of the possible metrics we introduced to evaluate the performance of a model. As seen in Module 2, there are other metrics that offer a more detailed view on the actual performance of the model. For example: precision, recall and F1-score offer insights on what kind of error we are incurring.\n",
    "\n",
    "**Question**: \n",
    "\n",
    "1. In the above case of the brain scans, what will be the precision and recall of the naive model that predicts healthy brain at 100% of the time?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "ypred = mp.predict(X)\n",
    "print classification_report(y, ypred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A more detailed view of the predictions for each class can be obtained by looking at the confusion matrix, which displays the actual number of cases that are predicted in to be in each class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "pd.DataFrame(confusion_matrix(y, ypred),\n",
    "             index = ['class 0 actual', 'class 1 actual'],\n",
    "             columns = ['class 0 pred', 'class 1 pred'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Undersampling\n",
    "When lots of data is present, a simple and effective strategy to deal with imbalance is to simply discard a random subset of the majority class, effectively undersampling it.\n",
    "- Pros: quick, easy to implement, lower load on model training because of less data\n",
    "- Cons: potentially losing important information\n",
    "\n",
    "Besides random undersampling, there are several other non-random ways to effectively undersample the majority class. The interested reader is referred to the references mentioned [here](https://github.com/fmfn/UnbalancedDataset)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from unbalanced_dataset import UnderSampler\n",
    "\n",
    "US = UnderSampler(verbose=False, random_state=0)\n",
    "usx, usy = US.fit_transform(X, y)\n",
    "usx_vis = pca.transform(usx)\n",
    "\n",
    "plt.scatter(usx_vis[usy==0, 0], usx_vis[usy==0, 1], label=\"Class #0\", alpha=0.5,\n",
    "            facecolor=palette[0], linewidth=0.15)\n",
    "plt.scatter(usx_vis[usy==1, 0], usx_vis[usy==1, 1], label=\"Class #1\", alpha=0.5,\n",
    "            facecolor=palette[2], linewidth=0.15)\n",
    "plt.title('Random under-sampling')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Oversampling\n",
    "Similarly, using more copies of the data in the minority class can also be an effective strategy.\n",
    "- Pros: retaining all available information\n",
    "- Cons: more data, not necessarily more information if minority class is not well represented"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from unbalanced_dataset import OverSampler\n",
    "ratio = float(np.count_nonzero(y==1)) / float(np.count_nonzero(y==0))\n",
    "\n",
    "OS = OverSampler(ratio=ratio, verbose=False, random_state=0)\n",
    "osx, osy = OS.fit_transform(X, y)\n",
    "osx_vis = pca.transform(osx)\n",
    "\n",
    "plt.scatter(osx_vis[osy==0, 0], osx_vis[osy==0, 1], label=\"Class #0\", alpha=0.5,\n",
    "            facecolor=palette[0], linewidth=0.15)\n",
    "plt.scatter(osx_vis[osy==1, 0], osx_vis[osy==1, 1], label=\"Class #1\", alpha=0.5,\n",
    "            facecolor=palette[2], linewidth=0.15)\n",
    "plt.title('Random over-sampling')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Synthetic data augmentation\n",
    "There are several techniques to create synthetic samples starting from the minority class. The most common are [SMOTE, Synthetic Minority Over-sampling Technique](http://www.jair.org/papers/paper953.html), and its variants. SMOTE creates synthetic samples from the minority class using a nearest neighbor technique. The algorithm selects two or more similar instances (using a distance measure) and it creates a new sample whose features are a linear combination of the neighbors features, with a random mixing parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from unbalanced_dataset import SMOTE\n",
    "\n",
    "smote = SMOTE(ratio=ratio, verbose=False, kind='regular', random_state=0)\n",
    "smox, smoy = smote.fit_transform(X, y)\n",
    "smox_vis = pca.transform(smox)\n",
    "plt.scatter(smox_vis[smoy==0, 0], smox_vis[smoy==0, 1], label=\"Class #0\", alpha=0.5,\n",
    "            facecolor=palette[0], linewidth=0.15)\n",
    "plt.scatter(smox_vis[smoy==1, 0], smox_vis[smoy==1, 1], label=\"Class #1\", alpha=0.5,\n",
    "            facecolor=palette[2], linewidth=0.15)\n",
    "plt.title('SMOTE')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Additional approaches\n",
    "\n",
    "In addition to using a metric sensitive to imbalance and to resampling the dataset in the attempt to rebalance the class ratio, it is possible to modify the model too. Options include:\n",
    "\n",
    "- **Use ROC curve** to evaluate how precision and recall are traded depending on the value of a threshold, if the classifier allows it. See [here for an example](http://scikit-learn.org/stable/auto_examples/model_selection/plot_roc.html#example-model-selection-plot-roc-py).\n",
    "\n",
    "- **Penalizing the majority class**: use a model that allows to set different weights for the different classes. See [here for an example](http://scikit-learn.org/stable/auto_examples/svm/plot_weighted_samples.html).\n",
    "\n",
    "- **Anomaly/outlier detection**: consider the problem as an anomaly detection problem and use the majority class to train a model. See [here for a couple of examples](http://scikit-learn.org/stable/modules/outlier_detection.html).\n",
    "\n",
    "\n",
    "Other ideas can be found [here](https://www.quora.com/In-classification-how-do-you-handle-an-unbalanced-training-set)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train/Test split with unbalanced data\n",
    "Any operation that alters the balance of the classes by adding samples for the minority class should only be performed on the training set. The test set should be left untouched, or possibly downsampled, but not oversampled. In particular, train/test split should never be performed *after* rebalancing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.5, random_state=3)\n",
    "\n",
    "estimator = KNeighborsClassifier(10)\n",
    "\n",
    "estimator.fit(X_train, y_train)\n",
    "ypred = estimator.predict(X_test)\n",
    "print classification_report(y_test, ypred)\n",
    "pd.DataFrame(confusion_matrix(y_test, ypred),\n",
    "             index = ['class 0 actual', 'class 1 actual'],\n",
    "             columns = ['class 0 pred', 'class 1 pred'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "smote = SMOTE(ratio=ratio, verbose=False, kind='regular', random_state=0)\n",
    "smox, smoy = smote.fit_transform(X_train, y_train)\n",
    "\n",
    "estimator.fit(smox, smoy)\n",
    "ypred = estimator.predict(X_test)\n",
    "print classification_report(y_test, ypred)\n",
    "pd.DataFrame(confusion_matrix(y_test, ypred),\n",
    "             index = ['class 0 actual', 'class 1 actual'],\n",
    "             columns = ['class 0 pred', 'class 1 pred'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "estimator = LogisticRegression()\n",
    "\n",
    "estimator.fit(X_train, y_train)\n",
    "ypred = estimator.predict(X_test)\n",
    "print classification_report(y_test, ypred)\n",
    "pd.DataFrame(confusion_matrix(y_test, ypred),\n",
    "             index = ['class 0 actual', 'class 1 actual'],\n",
    "             columns = ['class 0 pred', 'class 1 pred'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "smox, smoy = smote.fit_transform(X_train, y_train)\n",
    "\n",
    "estimator.fit(smox, smoy)\n",
    "ypred = estimator.predict(X_test)\n",
    "print classification_report(y_test, ypred)\n",
    "pd.DataFrame(confusion_matrix(y_test, ypred),\n",
    "             index = ['class 0 actual', 'class 1 actual'],\n",
    "             columns = ['class 0 pred', 'class 1 pred'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question**:\n",
    "\n",
    "1. what could happen if oversampling was done before train/test split?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Probabilities with unbalanced data\n",
    "\n",
    "Modifying the balance of the training dataset will affect the probabilities distributions learned by the estimator. We need to keep this in mind if we are predicting probabilities and not just the class.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "estimator = LogisticRegression()\n",
    "\n",
    "estimator.fit(X_train, y_train)\n",
    "(100.0*estimator.predict_proba(X_test)).round(1)[-10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "estimator.fit(smox, smoy)\n",
    "(100.0*estimator.predict_proba(X_test)).round(1)[-10:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The python Unbalanced Data package\n",
    "\n",
    "The [unbalanced dataset python package](https://github.com/fmfn/UnbalancedDataset) implements several techniques for rebalancing an unbalanced dataset and contains some examples of implementation.\n",
    "\n",
    "See further notes [here](http://stats.stackexchange.com/questions/131255/class-imbalance-in-supervised-machine-learning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exit Tickets\n",
    "\n",
    "1. What are some common causes for data imbalance?\n",
    "1. How can one deal with unbalanced dataset? List several ways with pros and cons\n",
    "1. What's wrong with resampling all the data before train/test split?\n",
    "1. How is Cross Validation performed in the case of unbalanced classes?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spoilers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Answers\n",
    "\n",
    "#### Precision/Recall\n",
    "1. for the healthy class, precision is 90%, recall is 100%. For the cancer class, precision and recall are both 0%.\n",
    "\n",
    "#### Resampling before train/test split\n",
    "1. copies of the same data point could be present in both the training and test set, increasing the risk of overfitting due to information leakage."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Copyright &copy; 2015 The Data Incubator.  All rights reserved.*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
