{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import seaborn as sns\n",
    "matplotlib.rcParams['savefig.dpi'] = 144"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Overview of Machine Learning\n",
    "<!-- requirement: images/plot_classifier_comparison.png -->\n",
    "<!-- requirement: images/ml_map.png -->\n",
    "\n",
    "**Machine Learning**: A computer program learns if it improves its __performance__ on some __task__ with __experience__.\n",
    "\n",
    "* __Task__: Machine learning tasks can be divided into two major types. \n",
    "\n",
    "    1. The first type is __supervised__, where we make predictions based on our data. Supervised machine learning tasks can be further broken down into \n",
    "        1. __regression__ tasks, where we make predictions that are continuous and ordered (ex: housing prices), and \n",
    "        1. __classification__ tasks, where we make predictions that are categorical and unordered (ex: whether a patient has a disease). \n",
    "    1. The second type is __unsupervised__, which we use to gain insight into the underlying data structure or to preprocess our data prior to building supervised models. Examples of unsupervised tasks include \n",
    "        1. clustering and \n",
    "        1. dimension reduction. \n",
    "        \n",
    "* __Performance__: We need to come up with a __metric__ to evaluate our model. Some metrics are errors (that we want to minimize) and others are scores (that we want to maximize). The type of metric we will choose depends on our task.\n",
    "\n",
    "    1. Regression: sum of squared error, absolute error, $R^2$\n",
    "    1. Classification: Accuracy and loss, precision and recall, AUC, ROC, log loss or cross entropy, Gini index\n",
    "    \n",
    "* __Experience__: Typically, we optimize our model by minimizing a loss or cost function. Doing so requires taking the derivative of our cost function with respect to our model __parameters__. If we do this process iteratively (usually in __batches__ via __Gradient Descent__) we say our model \"learns with experience.\" In some cases, however, we can solve for the optimal parameters without using gradient descent (ex: linear regression). Strictly speaking, our program is not \"learning\" in this senario. We use iterative, optimization techniques when we have lots of data that are streaming in or when large quantities of data makes computation difficult. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Decision-making flowchart\n",
    "\n",
    "A few factors to consider:\n",
    "1. What are you trying to predict?  Should the algorithm be a classification, regression, or clustering problem? Should you use a linear or non-linear model?\n",
    "1. How does the algorithm scale to larger datasets in terms of both **memory** or **time**.  Does this make the computation infeasible?\n",
    "1. Is there an **iterative** (versus **batch**) version of this algorithm?  Is **online learning** or **streaming** possible?\n",
    "1. Do you have to worry about explicability?\n",
    "1. Are there many features?  If there are, do you want to reduce the dimension (e.g. PCA or Lasso)?\n",
    "1. **Accuracy**: does the algorithm tend to underfit (e.g. it doesn't satisfy the asymptotic approximation property)?  A fixed model form is less able to take advantage of more data than a flexible model form.\n",
    "1. Does the \"prior\" you're introducing with a **parametric** model make sense for your dataset?\n",
    "1. Are you working with timeseries data and wish to do forecasting?\n",
    "1. Are you building a classifier with unbalanced classes? How are you dealing with outliers? Anomalies? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Performance considerations can often be nuanced.\n",
    "\n",
    "* Neural Networks train faster than SVMs (at least three reasons why?)\n",
    "* SVMs predict faster than Neural Networks (why?)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Comparing ML Algorithms\n",
    "\n",
    "It's important to be able to clearly understand and explain the theoretical and practical differences between machine learning algorithms. This notebook (for now) is a collection of resources to help you understand the landscape of algorithms as a whole."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "This flowchart ([interactive source](http://scikit-learn.org/stable/tutorial/machine_learning_map/)) has some good examples of the kinds of criteria one needs to be thinking about when choosing an algorithm.\n",
    "![Machine learning flowchart from the scikit-learn documentation](images/ml_map.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Notes on individual models:\n",
    "\n",
    "#### Decision Trees\n",
    "* Can be used for outlier detection\n",
    "* Can easily explain\n",
    "* Random forests scale well if you want to update model with new data\n",
    "* Can be slow when it comes to predicting (if you have lots of branches)\n",
    "* Works well for high dimensional feature spaces\n",
    "* Gradient boosting and random forests perform well with large datasets \n",
    "\n",
    "#### Support Vector Machines\n",
    "* Good with limited data\n",
    "* Can be used for outlier detection \n",
    "* Better performance with outliers compared to linear regression\n",
    "* Cannot stream data in\n",
    "* Fast when predicting\n",
    "* Good with non-linear problems\n",
    "\n",
    "#### Naive Bayes\n",
    "* Can easily explain\n",
    "* Works well if you have small amounts of data\n",
    "* Usually computationally costly\n",
    "* Working under the assumption that your features are independent (where \"naive\" part comes from)\n",
    "* Bayesian methods are an important concept in generative models\n",
    "\n",
    "#### Neural Network\n",
    "* Good for non-linear classification/regression problems\n",
    "* Slow to train\n",
    "* Fast to run\n",
    "* Forms the basis of deep, hierarchical modeling. \n",
    "\n",
    "#### K Nearest Neighbors\n",
    "* Simple to explain\n",
    "* Slow and memory inefficient\n",
    "* Not great for high dimensional feature space (due to computational complexity)\n",
    "\n",
    "#### Linear Regression ( Ridge or Lasso) and Logistic Regression\n",
    "* Good for interpreting the relationship between independent and dependent variables\n",
    "* Can perform feature importance with ridge and lasso\n",
    "* Making an assumption about the distribution of your noise (about your signal)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Overfitting\n",
    "\n",
    "After you have selected a ML algorithm, you need to ensure that your model is generalizable (or that you are not overfitting the model to your data). Overfitting is when the model captures the noise rather than the underlying signal in the data and occurs when the model is too complex -- it is trained with too many features relative to the number of observations or it has an involved architecture. To prevent overfitting\n",
    "\n",
    "1. Break your data into __training__ and __test sets__ and perform __(cross-)validation__ to find the best __hyperparameters__ (that dictate your model's architecture). \n",
    "1. Cut down on the number of features by performing a __feature importance__ analysis. You can do this with\n",
    "    1. Optimizing $\\alpha$ in the ridge or lasso regression algorithm\n",
    "    1. Clustering\n",
    "    1. PCA\n",
    "    1. Decision trees\n",
    "    1. Droping or shuffling columns\n",
    "\n",
    "_After you cross-validate your model, remember to retrain it on the entire dataset!_ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Scaling, Normalization, and Standardization\n",
    "\n",
    "It is important to scale your features when you are\n",
    "1. Working with algorithms that use Euclidean distance measures (ex: K-Nearest Neighbor and K-Means)\n",
    "1. Performing dimension reduction techniques like PCA, where you want to find the direction of maximum variance in your dataset. Larger scaled features will have greater influences on the principle components. \n",
    "\n",
    "Ways you can scale your features include:\n",
    "1. Subtracting out the mean and dividing by the standard deviation.\n",
    "1. Fixing the range."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Ensemble methods\n",
    "Combining models can improve the accuracy of your predictions. For decision trees, remember that progressing from decision trees -> random forests -> gradient-boosting trees\n",
    "1. increases accuracy\n",
    "1. decreases explicability\n",
    "1. increases computation time/memory footprint (boosting algorithms can't be parallelized)\n",
    "\n",
    "### Bagging\n",
    "Random forests demonstrate the idea of bootstrap aggregation, or bagging. Each individual model has an equal vote in the ensemble, and you have the freedom to skew the weak learners towards higher variance, knowing that the averaging will (ideally) wash out the randomness and prevent overfitting.\n",
    "\n",
    "### Boosting\n",
    "Gradient boosting trees demonstrate the power of training on the residual from your own predictions in order to achieve very good prediction metrics. Other boosting algorithms offer similar benefits, as well as similar drawbacks. Beware of overfitting here.\n",
    "\n",
    "### Blending\n",
    "The FeatureUnion full_model you implemented in ml.py is an example of combining the predictions of many (usually simple) models and passing them as features to a final regressor or classifier. Using a linear model is equivalent to taking a weighted average of the contributors, whereas a more complex final estimator is capable of combining the component models nonlinearly. In general, the explicability of these techniques is slightly better than a \"black box\" algorithm like a neural network.\n",
    "\n",
    "You might notice that in eg. Kaggle competitions, many of the winning entries are based on ensemble models. Ensembles tend to outperform individual models, but require careful tuning of each of the components, as well as more computational power."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "This image ([source code](http://scikit-learn.org/stable/auto_examples/classification/plot_classifier_comparison.html)) shows how various scikit-learn classifers fit their models for a few different configurations of training data.\n",
    "![Comparison of various scikit-learn classifiers from the official documentation](images/plot_classifier_comparison.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Modeling for purposes other than predictive power\n",
    "You might think after learning about complex classification models: \"why would anyone ever use plain old logistic regression?\" It's important to remember that the probabilistic output of logistic regression is valuable in certain circumstances. In general, consider that beyond just comparing error metrics with other algorithms, you may sometimes want to compare output with entirely different methods of analysis - for example, if you're working with an actuary.\n",
    "\n",
    "Finally remember that there is often value in understanding your features regardless of their predictive power. Certain algorithms will reveal more about the input features than others."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "**Spoilers**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Training comparison\n",
    "1. SVMs require solving the dual Lagrangian (quadratic optimization) as opposed to the primal Lagrangian\n",
    "1. Multiclass classification for SVMs requires one-vs-one or one-vs-all, either is more time-consuming than a NN\n",
    "1. NN training is an embarrassingly parallel problem. Parallelizing SVM training is not trivial (although possible)\n",
    "\n",
    "Prediction comparison\n",
    "1. Linear SVM requires only a dot product calculation to check which side of the decision boundary the data point is on. NN requires propagating the data through the network (multiple matrix multiplications). SVM kernels scale with the number of support vectors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "*Copyright &copy; 2015 The Data Incubator.  All rights reserved.*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
