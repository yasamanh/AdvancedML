{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import seaborn as sns\n",
    "matplotlib.rcParams['savefig.dpi'] = 144"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import grader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Classifing Music by Genre\n",
    "\n",
    "Music offers an extremely rich and interesting playing field. The objective of this miniproject is to develop models that are able to recognize the genre of a musical piece, first from pre-computed features and then working from the raw waveform. This is a typical example of a classification problem on time series data.\n",
    "\n",
    "Each piece has been classified to belong to one of the following genres:\n",
    "- electronic\n",
    "- folkcountry\n",
    "- jazz\n",
    "- raphiphop\n",
    "- rock\n",
    "\n",
    "The model will be assessed based on the accuracy score of your classifier.  There is a reference solution.  The reference solution has a score of 1. *(Note that this doesn't mean that the accuracy of the reference solution is 1)*. Keeping this in mind...\n",
    "\n",
    "## A note on scoring\n",
    "It **is** possible to score >1 on these questions. This indicates that you've beaten our reference model - we compare our model's score on a test set to your score on a test set. See how high you can go!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Questions\n",
    "\n",
    "\n",
    "## Question 1: All Features Model\n",
    "Download a set of pre-computed features from Amazon S3:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "download: s3://dataincubator-course/mldata/df_train_anon.csv to ./df_train_anon.csv\n"
     ]
    }
   ],
   "source": [
    "!aws s3 sync s3://dataincubator-course/mldata/ . --exclude '*' --include 'df_train_anon.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "This file contains 549 pre-computed features for the training set. The last column contains the genre.\n",
    "\n",
    "Build a model to generate predictions from this feature set. Steps in the pipeline could include:\n",
    "\n",
    "- a normalization step (not all features have the same size or distribution)\n",
    "- a dimensionality reduction or feature selection step\n",
    "- ... any other transformer you may find relevant ...\n",
    "- an estimator\n",
    "- a label encoder inverse transform to return the genre as a string\n",
    "\n",
    "Use GridSearchCV to find the scikit learn estimator with the best cross-validated performance.\n",
    "\n",
    "*Hints:*\n",
    "- Scikit Learn's [StandardScaler](http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html) can center the data and/or scale by the standard deviation.\n",
    "- Use a dimensionality reduction technique (e.g. [PCA](http://scikit-learn.org/stable/modules/generated/sklearn.decomposition.PCA.html)) or a feature selection criteria when possible.\n",
    "- Use [GridSearchCV](http://scikit-learn.org/0.17/modules/generated/sklearn.grid_search.GridSearchCV.html#sklearn.grid_search.GridSearchCV) to improve score.\n",
    "- Use a [LabelEncoder](http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.LabelEncoder.html) to generate an encoding for the labels.\n",
    "- The model needs to return the genre as a string. You may need to create a wrapper class around scikit-learn estimators in order to do that.\n",
    "\n",
    "Submit a function that takes a list of records, each a list of the 549 features, and returns a list of genre predictions, one for each record."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"df_train_anon.csv\",header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>540</th>\n",
       "      <th>541</th>\n",
       "      <th>542</th>\n",
       "      <th>543</th>\n",
       "      <th>544</th>\n",
       "      <th>545</th>\n",
       "      <th>546</th>\n",
       "      <th>547</th>\n",
       "      <th>548</th>\n",
       "      <th>549</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.008931</td>\n",
       "      <td>0.000089</td>\n",
       "      <td>6.483444</td>\n",
       "      <td>57.936259</td>\n",
       "      <td>0.006836</td>\n",
       "      <td>0.001953</td>\n",
       "      <td>0.120605</td>\n",
       "      <td>0.008816</td>\n",
       "      <td>0.000084</td>\n",
       "      <td>3.814679</td>\n",
       "      <td>...</td>\n",
       "      <td>0.292633</td>\n",
       "      <td>0.235038</td>\n",
       "      <td>0.210596</td>\n",
       "      <td>0.189853</td>\n",
       "      <td>0.172447</td>\n",
       "      <td>0.172212</td>\n",
       "      <td>0.174138</td>\n",
       "      <td>0.173343</td>\n",
       "      <td>99.384014</td>\n",
       "      <td>jazz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.009044</td>\n",
       "      <td>0.000141</td>\n",
       "      <td>7.253759</td>\n",
       "      <td>66.717846</td>\n",
       "      <td>0.005859</td>\n",
       "      <td>0.002441</td>\n",
       "      <td>0.147949</td>\n",
       "      <td>0.008619</td>\n",
       "      <td>0.000068</td>\n",
       "      <td>3.203744</td>\n",
       "      <td>...</td>\n",
       "      <td>0.561459</td>\n",
       "      <td>0.551483</td>\n",
       "      <td>0.544794</td>\n",
       "      <td>0.552135</td>\n",
       "      <td>0.576745</td>\n",
       "      <td>0.581951</td>\n",
       "      <td>0.578048</td>\n",
       "      <td>0.578411</td>\n",
       "      <td>123.046875</td>\n",
       "      <td>jazz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.009094</td>\n",
       "      <td>0.000082</td>\n",
       "      <td>7.845424</td>\n",
       "      <td>71.890004</td>\n",
       "      <td>0.006836</td>\n",
       "      <td>0.002930</td>\n",
       "      <td>0.106445</td>\n",
       "      <td>0.008814</td>\n",
       "      <td>0.000056</td>\n",
       "      <td>3.803823</td>\n",
       "      <td>...</td>\n",
       "      <td>0.325219</td>\n",
       "      <td>0.347016</td>\n",
       "      <td>0.365914</td>\n",
       "      <td>0.369968</td>\n",
       "      <td>0.348162</td>\n",
       "      <td>0.334928</td>\n",
       "      <td>0.352339</td>\n",
       "      <td>0.350118</td>\n",
       "      <td>109.956782</td>\n",
       "      <td>electronic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.009234</td>\n",
       "      <td>0.000082</td>\n",
       "      <td>5.243707</td>\n",
       "      <td>43.529571</td>\n",
       "      <td>0.007324</td>\n",
       "      <td>0.001953</td>\n",
       "      <td>0.105469</td>\n",
       "      <td>0.009056</td>\n",
       "      <td>0.000053</td>\n",
       "      <td>2.560825</td>\n",
       "      <td>...</td>\n",
       "      <td>0.109804</td>\n",
       "      <td>0.102941</td>\n",
       "      <td>0.137016</td>\n",
       "      <td>0.185714</td>\n",
       "      <td>0.202237</td>\n",
       "      <td>0.142240</td>\n",
       "      <td>0.102227</td>\n",
       "      <td>0.143689</td>\n",
       "      <td>178.205819</td>\n",
       "      <td>jazz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.009895</td>\n",
       "      <td>0.000092</td>\n",
       "      <td>9.996839</td>\n",
       "      <td>110.425882</td>\n",
       "      <td>0.008789</td>\n",
       "      <td>0.001953</td>\n",
       "      <td>0.136719</td>\n",
       "      <td>0.009625</td>\n",
       "      <td>0.000069</td>\n",
       "      <td>3.137464</td>\n",
       "      <td>...</td>\n",
       "      <td>0.087319</td>\n",
       "      <td>0.062016</td>\n",
       "      <td>0.051776</td>\n",
       "      <td>0.046376</td>\n",
       "      <td>0.039522</td>\n",
       "      <td>0.046094</td>\n",
       "      <td>0.063596</td>\n",
       "      <td>0.207312</td>\n",
       "      <td>120.185320</td>\n",
       "      <td>electronic</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 550 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0         1         2           3         4         5         6    \\\n",
       "0  0.008931  0.000089  6.483444   57.936259  0.006836  0.001953  0.120605   \n",
       "1  0.009044  0.000141  7.253759   66.717846  0.005859  0.002441  0.147949   \n",
       "2  0.009094  0.000082  7.845424   71.890004  0.006836  0.002930  0.106445   \n",
       "3  0.009234  0.000082  5.243707   43.529571  0.007324  0.001953  0.105469   \n",
       "4  0.009895  0.000092  9.996839  110.425882  0.008789  0.001953  0.136719   \n",
       "\n",
       "        7         8         9       ...           540       541       542  \\\n",
       "0  0.008816  0.000084  3.814679     ...      0.292633  0.235038  0.210596   \n",
       "1  0.008619  0.000068  3.203744     ...      0.561459  0.551483  0.544794   \n",
       "2  0.008814  0.000056  3.803823     ...      0.325219  0.347016  0.365914   \n",
       "3  0.009056  0.000053  2.560825     ...      0.109804  0.102941  0.137016   \n",
       "4  0.009625  0.000069  3.137464     ...      0.087319  0.062016  0.051776   \n",
       "\n",
       "        543       544       545       546       547         548         549  \n",
       "0  0.189853  0.172447  0.172212  0.174138  0.173343   99.384014        jazz  \n",
       "1  0.552135  0.576745  0.581951  0.578048  0.578411  123.046875        jazz  \n",
       "2  0.369968  0.348162  0.334928  0.352339  0.350118  109.956782  electronic  \n",
       "3  0.185714  0.202237  0.142240  0.102227  0.143689  178.205819        jazz  \n",
       "4  0.046376  0.039522  0.046094  0.063596  0.207312  120.185320  electronic  \n",
       "\n",
       "[5 rows x 550 columns]"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "550"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df.loc[0:549])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(df.loc[:,0:548],df[549])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3, 3])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = pd.factorize(y_train)[0]\n",
    "labels[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1141           rock\n",
       "20       electronic\n",
       "723       raphiphop\n",
       "174     folkcountry\n",
       "409     folkcountry\n",
       "961            rock\n",
       "998            jazz\n",
       "398            jazz\n",
       "119       raphiphop\n",
       "1031           rock\n",
       "Name: 549, dtype: object"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "dict_genre={0:\"rock\",1:\"electronic\",2:\"raphiphop\",3:\"folkcountry\",4:\"jazz\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_split=1e-07, min_samples_leaf=5,\n",
       "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "            n_estimators=10, n_jobs=1, oob_score=False, random_state=None,\n",
       "            verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = RandomForestClassifier(min_samples_leaf=5)\n",
    "clf.fit(X_train, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def all_features(records):\n",
    "    labels = clf.predict(records)\n",
    "    return [dict_genre[r] for r in labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "t = all_features(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['jazz',\n",
       " 'jazz',\n",
       " 'rock',\n",
       " 'rock',\n",
       " 'jazz',\n",
       " 'jazz',\n",
       " 'folkcountry',\n",
       " 'rock',\n",
       " 'jazz',\n",
       " 'rock',\n",
       " 'jazz',\n",
       " 'raphiphop',\n",
       " 'raphiphop',\n",
       " 'jazz',\n",
       " 'raphiphop',\n",
       " 'rock',\n",
       " 'rock',\n",
       " 'raphiphop',\n",
       " 'raphiphop',\n",
       " 'jazz',\n",
       " 'rock',\n",
       " 'jazz',\n",
       " 'jazz',\n",
       " 'rock',\n",
       " 'rock',\n",
       " 'raphiphop',\n",
       " 'jazz',\n",
       " 'raphiphop',\n",
       " 'rock',\n",
       " 'rock',\n",
       " 'jazz',\n",
       " 'rock',\n",
       " 'rock',\n",
       " 'jazz',\n",
       " 'rock',\n",
       " 'jazz',\n",
       " 'jazz',\n",
       " 'rock',\n",
       " 'rock',\n",
       " 'raphiphop',\n",
       " 'rock',\n",
       " 'jazz',\n",
       " 'jazz',\n",
       " 'jazz',\n",
       " 'raphiphop',\n",
       " 'folkcountry',\n",
       " 'raphiphop',\n",
       " 'rock',\n",
       " 'rock',\n",
       " 'raphiphop',\n",
       " 'folkcountry',\n",
       " 'folkcountry',\n",
       " 'raphiphop',\n",
       " 'raphiphop',\n",
       " 'folkcountry',\n",
       " 'raphiphop',\n",
       " 'rock',\n",
       " 'rock',\n",
       " 'rock',\n",
       " 'jazz',\n",
       " 'jazz',\n",
       " 'jazz',\n",
       " 'raphiphop',\n",
       " 'rock',\n",
       " 'rock',\n",
       " 'folkcountry',\n",
       " 'electronic',\n",
       " 'rock',\n",
       " 'folkcountry',\n",
       " 'rock',\n",
       " 'raphiphop',\n",
       " 'rock',\n",
       " 'rock',\n",
       " 'rock',\n",
       " 'raphiphop',\n",
       " 'rock',\n",
       " 'raphiphop',\n",
       " 'rock',\n",
       " 'jazz',\n",
       " 'jazz',\n",
       " 'raphiphop',\n",
       " 'rock',\n",
       " 'rock',\n",
       " 'jazz',\n",
       " 'jazz',\n",
       " 'rock',\n",
       " 'jazz',\n",
       " 'rock',\n",
       " 'rock',\n",
       " 'rock',\n",
       " 'folkcountry',\n",
       " 'jazz',\n",
       " 'jazz',\n",
       " 'jazz',\n",
       " 'rock',\n",
       " 'rock',\n",
       " 'jazz',\n",
       " 'folkcountry',\n",
       " 'jazz',\n",
       " 'rock',\n",
       " 'folkcountry',\n",
       " 'jazz',\n",
       " 'folkcountry',\n",
       " 'raphiphop',\n",
       " 'folkcountry',\n",
       " 'jazz',\n",
       " 'rock',\n",
       " 'rock',\n",
       " 'jazz',\n",
       " 'rock',\n",
       " 'jazz',\n",
       " 'rock',\n",
       " 'jazz',\n",
       " 'jazz',\n",
       " 'jazz',\n",
       " 'rock',\n",
       " 'raphiphop',\n",
       " 'raphiphop',\n",
       " 'rock',\n",
       " 'raphiphop',\n",
       " 'rock',\n",
       " 'rock',\n",
       " 'raphiphop',\n",
       " 'rock',\n",
       " 'raphiphop',\n",
       " 'rock',\n",
       " 'jazz',\n",
       " 'rock',\n",
       " 'jazz',\n",
       " 'jazz',\n",
       " 'raphiphop',\n",
       " 'raphiphop',\n",
       " 'electronic',\n",
       " 'raphiphop',\n",
       " 'jazz',\n",
       " 'raphiphop',\n",
       " 'raphiphop',\n",
       " 'rock',\n",
       " 'rock',\n",
       " 'jazz',\n",
       " 'raphiphop',\n",
       " 'jazz',\n",
       " 'jazz',\n",
       " 'raphiphop',\n",
       " 'raphiphop',\n",
       " 'jazz',\n",
       " 'rock',\n",
       " 'folkcountry',\n",
       " 'jazz',\n",
       " 'raphiphop',\n",
       " 'jazz',\n",
       " 'raphiphop',\n",
       " 'rock',\n",
       " 'folkcountry',\n",
       " 'rock',\n",
       " 'raphiphop',\n",
       " 'rock',\n",
       " 'rock',\n",
       " 'rock',\n",
       " 'rock',\n",
       " 'rock',\n",
       " 'jazz',\n",
       " 'rock',\n",
       " 'rock',\n",
       " 'jazz',\n",
       " 'jazz',\n",
       " 'jazz',\n",
       " 'rock',\n",
       " 'rock',\n",
       " 'rock',\n",
       " 'rock',\n",
       " 'folkcountry',\n",
       " 'jazz',\n",
       " 'jazz',\n",
       " 'raphiphop',\n",
       " 'rock',\n",
       " 'jazz',\n",
       " 'jazz',\n",
       " 'raphiphop',\n",
       " 'jazz',\n",
       " 'raphiphop',\n",
       " 'folkcountry',\n",
       " 'rock',\n",
       " 'folkcountry',\n",
       " 'jazz',\n",
       " 'raphiphop',\n",
       " 'rock',\n",
       " 'rock',\n",
       " 'jazz',\n",
       " 'rock',\n",
       " 'rock',\n",
       " 'jazz',\n",
       " 'raphiphop',\n",
       " 'jazz',\n",
       " 'raphiphop',\n",
       " 'rock',\n",
       " 'jazz',\n",
       " 'rock',\n",
       " 'jazz',\n",
       " 'raphiphop',\n",
       " 'jazz',\n",
       " 'jazz',\n",
       " 'jazz',\n",
       " 'rock',\n",
       " 'jazz',\n",
       " 'raphiphop',\n",
       " 'jazz',\n",
       " 'rock',\n",
       " 'raphiphop',\n",
       " 'rock',\n",
       " 'raphiphop',\n",
       " 'rock',\n",
       " 'rock',\n",
       " 'rock',\n",
       " 'jazz',\n",
       " 'folkcountry',\n",
       " 'raphiphop',\n",
       " 'jazz',\n",
       " 'raphiphop',\n",
       " 'rock',\n",
       " 'folkcountry',\n",
       " 'folkcountry',\n",
       " 'rock',\n",
       " 'jazz',\n",
       " 'rock',\n",
       " 'raphiphop',\n",
       " 'electronic',\n",
       " 'rock',\n",
       " 'rock',\n",
       " 'rock',\n",
       " 'electronic',\n",
       " 'jazz',\n",
       " 'rock',\n",
       " 'jazz',\n",
       " 'raphiphop',\n",
       " 'folkcountry',\n",
       " 'jazz',\n",
       " 'jazz',\n",
       " 'rock',\n",
       " 'raphiphop',\n",
       " 'folkcountry',\n",
       " 'rock',\n",
       " 'jazz',\n",
       " 'jazz',\n",
       " 'jazz',\n",
       " 'rock',\n",
       " 'jazz',\n",
       " 'raphiphop',\n",
       " 'jazz',\n",
       " 'jazz',\n",
       " 'rock',\n",
       " 'raphiphop',\n",
       " 'rock',\n",
       " 'raphiphop',\n",
       " 'raphiphop',\n",
       " 'rock',\n",
       " 'rock',\n",
       " 'jazz',\n",
       " 'rock',\n",
       " 'rock',\n",
       " 'rock',\n",
       " 'jazz',\n",
       " 'raphiphop',\n",
       " 'rock',\n",
       " 'raphiphop',\n",
       " 'folkcountry',\n",
       " 'raphiphop',\n",
       " 'jazz',\n",
       " 'jazz',\n",
       " 'raphiphop',\n",
       " 'rock',\n",
       " 'rock',\n",
       " 'jazz',\n",
       " 'rock',\n",
       " 'folkcountry',\n",
       " 'rock',\n",
       " 'raphiphop',\n",
       " 'jazz',\n",
       " 'rock',\n",
       " 'raphiphop',\n",
       " 'raphiphop',\n",
       " 'folkcountry',\n",
       " 'raphiphop',\n",
       " 'rock',\n",
       " 'raphiphop',\n",
       " 'rock',\n",
       " 'jazz',\n",
       " 'jazz',\n",
       " 'folkcountry',\n",
       " 'rock',\n",
       " 'jazz',\n",
       " 'jazz']"
      ]
     },
     "execution_count": 290,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'folkcountry'"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict_genre[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================\n",
      "Your score:  0.908333333355\n",
      "==================\n"
     ]
    }
   ],
   "source": [
    "# def all_features_est(records):\n",
    "#     return ['blues' for r in records]\n",
    "\n",
    "# grader.score('music__all_features_model', all_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Question 2: Raw Features Predictions\n",
    "\n",
    "For questions 2 and 3, you will need to extract features from raw audio.  Because this extraction can be rather time-consuming, you will not conduct the feature extraction of the test set in real time during the grading.\n",
    "\n",
    "Instead, you will download a set of test files.  After you have trained your model, you will run it on the test files, to make a prediction for each.  Then submit to the grader a dictionary of the form\n",
    "\n",
    "```python\n",
    "{\n",
    "  \"fe_test_0001.mp3\": \"electronic\",\n",
    "  \"fe_test_0002.mp3\": \"rock\",\n",
    "  ...\n",
    "}\n",
    "```\n",
    "\n",
    "A sets of files for training and testing are available on Amazon S3:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "download: s3://dataincubator-course/mldata/music_feature_extraction_test.tar.gz to ./music_feature_extraction_test.tar.gz\n",
      "download: s3://dataincubator-course/mldata/music_train_labels.csv to ./music_train_labels.csv\n",
      "download: s3://dataincubator-course/mldata/music_train.tar.gz to ./music_train.tar.gz\n"
     ]
    }
   ],
   "source": [
    "# Training files\n",
    "!aws s3 sync s3://dataincubator-course/mldata/ . --exclude '*' \\\n",
    "    --include 'music_train.tar.gz' \\\n",
    "    --include 'music_train_labels.csv' \\\n",
    "    --include 'music_feature_extraction_test.tar.gz'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import librosa\n",
    "# import librosa #.feature.zero_crossing_rate\n",
    "# import librosa #.feature.rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import tarfile\n",
    "\n",
    "t = tarfile.open('music_train.tar', 'r')\n",
    "# print t.getnames()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "mono, fs = librosa.load('data/train/train_0001.mp3', sr = 44100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "zcr = librosa.feature.zero_crossing_rate(mono)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 353,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmse = librosa.feature.rmse(mono)\n",
    "len(rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# mono, fs = librosa.load(f, sr = None)\n",
    "zcr = librosa.feature.zero_crossing_rate(mono)\n",
    "rmse = librosa.feature.rmse(mono)\n",
    "tempo, beat = librosa.beat.beat_track(mono,hop_length=256)\n",
    "mfcc = librosa.feature.mfcc(mono,sr=44100)\n",
    "delta_mfcc = librosa.feature.delta(mfcc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "object of type 'numpy.float64' has no len()",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-360-7c96c681200e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdelta_mfcc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: object of type 'numpy.float64' has no len()"
     ]
    }
   ],
   "source": [
    "len(np.mean(delta_mfcc.mean(axis=1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.04212356"
      ]
     },
     "execution_count": 363,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.std(rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "mfcc = librosa.feature.mfcc(mono,sr=44100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-4.8529844026803239"
      ]
     },
     "execution_count": 271,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l[19]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-176.16666883807429,\n",
       " 152.82696025947527,\n",
       " -40.404001542526224,\n",
       " 44.473942579295418,\n",
       " -6.9547758979535486,\n",
       " 24.830904429872433,\n",
       " -19.696804668467674,\n",
       " 17.167506412655509,\n",
       " -9.8134965801073921,\n",
       " 3.4701912407945863,\n",
       " -0.80063359334406448,\n",
       " -5.954915128951022,\n",
       " -8.3172745830374399,\n",
       " -1.9527064181899951,\n",
       " -4.5052767654051689,\n",
       " -11.227108012843939,\n",
       " 3.4384566398038321,\n",
       " -3.8638007366205063,\n",
       " 2.2215932970622188,\n",
       " -4.8529844026803239]"
      ]
     },
     "execution_count": 279,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l = [np.mean(mfcc[i]) for i in range(0,20)]\n",
    "l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "d={'MFCC__%d' % i: value for (i, value) in enumerate(l)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'MFCC__0': -176.16666883807429,\n",
       " 'MFCC__1': 152.82696025947527,\n",
       " 'MFCC__10': -0.80063359334406448,\n",
       " 'MFCC__11': -5.954915128951022,\n",
       " 'MFCC__12': -8.3172745830374399,\n",
       " 'MFCC__13': -1.9527064181899951,\n",
       " 'MFCC__14': -4.5052767654051689,\n",
       " 'MFCC__15': -11.227108012843939,\n",
       " 'MFCC__16': 3.4384566398038321,\n",
       " 'MFCC__17': -3.8638007366205063,\n",
       " 'MFCC__18': 2.2215932970622188,\n",
       " 'MFCC__19': -4.8529844026803239,\n",
       " 'MFCC__2': -40.404001542526224,\n",
       " 'MFCC__3': 44.473942579295418,\n",
       " 'MFCC__4': -6.9547758979535486,\n",
       " 'MFCC__5': 24.830904429872433,\n",
       " 'MFCC__6': -19.696804668467674,\n",
       " 'MFCC__7': 17.167506412655509,\n",
       " 'MFCC__8': -9.8134965801073921,\n",
       " 'MFCC__9': 3.4701912407945863}"
      ]
     },
     "execution_count": 282,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "df_labels = pd.read_csv(\"music_train_labels.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "g_labels = [dict_genre[r] for r in df_labels['genre']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "df_labels_fac = pd.factorize(df_labels['genre'])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 1, 1, 0, 1, 0, 2, 3, 4])"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_labels_fac[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "dict2_genre={0:\"folkcountry\",1:\"jazz\",2:\"rock\",3:\"raphiphop\",4:\"electronic\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def feature_eng(t):\n",
    "    rmse_list_s=[]\n",
    "    zcr_list_s=[]\n",
    "\n",
    "    rmse_list_m=[]\n",
    "    zcr_list_m=[]\n",
    "\n",
    "    for f in t.getnames():\n",
    "        mono, fs = librosa.load(f, sr = None)\n",
    "        zcr = librosa.feature.zero_crossing_rate(mono)\n",
    "        rmse = librosa.feature.rmse(mono)\n",
    "\n",
    "        rmse_m = np.mean(rmse)\n",
    "        zcr_m = np.mean(zcr)\n",
    "\n",
    "        rmse_s = np.std(rmse)\n",
    "        zcr_s = np.std(zcr)\n",
    "\n",
    "        rmse_list_m.append(rmse_m)\n",
    "        zcr_list_m.append(zcr_m)\n",
    "\n",
    "        rmse_list_s.append(rmse_s)\n",
    "        zcr_list_s.append(zcr_s)\n",
    "\n",
    "    features_pd = pd.DataFrame(\n",
    "        {'RMSE_M': rmse_list_m,\n",
    "         'ZCR_M': zcr_list_m,\n",
    "         'RMSE_S': rmse_list_s,\n",
    "         'ZCR_S': zcr_list_s\n",
    "         })\n",
    "    return features_pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.04212356"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmse_list_s[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_split=1e-07, min_samples_leaf=20,\n",
       "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "            n_estimators=10, n_jobs=1, oob_score=False, random_state=None,\n",
       "            verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_q2 = RandomForestClassifier(min_samples_leaf=20)\n",
    "clf_q2.fit(feature_eng(t), df_labels_fac)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "t1 = tarfile.open('music_feature_extraction_test.tar', 'r')\n",
    "#print t1.getnames()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "test_labels = clf_q2.predict(feature_eng(t1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_labels[144]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fe_test_0001.mp3': 'raphiphop',\n",
       " 'fe_test_0002.mp3': 'raphiphop',\n",
       " 'fe_test_0003.mp3': 'electronic',\n",
       " 'fe_test_0004.mp3': 'raphiphop',\n",
       " 'fe_test_0005.mp3': 'raphiphop',\n",
       " 'fe_test_0006.mp3': 'raphiphop',\n",
       " 'fe_test_0007.mp3': 'raphiphop',\n",
       " 'fe_test_0008.mp3': 'raphiphop',\n",
       " 'fe_test_0009.mp3': 'raphiphop',\n",
       " 'fe_test_0010.mp3': 'folkcountry',\n",
       " 'fe_test_0011.mp3': 'electronic',\n",
       " 'fe_test_0012.mp3': 'raphiphop',\n",
       " 'fe_test_0013.mp3': 'raphiphop',\n",
       " 'fe_test_0014.mp3': 'raphiphop',\n",
       " 'fe_test_0015.mp3': 'raphiphop',\n",
       " 'fe_test_0016.mp3': 'raphiphop',\n",
       " 'fe_test_0017.mp3': 'folkcountry',\n",
       " 'fe_test_0018.mp3': 'folkcountry',\n",
       " 'fe_test_0019.mp3': 'electronic',\n",
       " 'fe_test_0020.mp3': 'raphiphop',\n",
       " 'fe_test_0021.mp3': 'electronic',\n",
       " 'fe_test_0022.mp3': 'raphiphop',\n",
       " 'fe_test_0023.mp3': 'raphiphop',\n",
       " 'fe_test_0024.mp3': 'electronic',\n",
       " 'fe_test_0025.mp3': 'raphiphop',\n",
       " 'fe_test_0026.mp3': 'raphiphop',\n",
       " 'fe_test_0027.mp3': 'raphiphop',\n",
       " 'fe_test_0028.mp3': 'folkcountry',\n",
       " 'fe_test_0029.mp3': 'electronic',\n",
       " 'fe_test_0030.mp3': 'folkcountry',\n",
       " 'fe_test_0031.mp3': 'raphiphop',\n",
       " 'fe_test_0032.mp3': 'electronic',\n",
       " 'fe_test_0033.mp3': 'electronic',\n",
       " 'fe_test_0034.mp3': 'electronic',\n",
       " 'fe_test_0035.mp3': 'raphiphop',\n",
       " 'fe_test_0036.mp3': 'raphiphop',\n",
       " 'fe_test_0037.mp3': 'raphiphop',\n",
       " 'fe_test_0038.mp3': 'electronic',\n",
       " 'fe_test_0039.mp3': 'folkcountry',\n",
       " 'fe_test_0040.mp3': 'raphiphop',\n",
       " 'fe_test_0041.mp3': 'electronic',\n",
       " 'fe_test_0042.mp3': 'raphiphop',\n",
       " 'fe_test_0043.mp3': 'electronic',\n",
       " 'fe_test_0044.mp3': 'electronic',\n",
       " 'fe_test_0045.mp3': 'raphiphop',\n",
       " 'fe_test_0046.mp3': 'electronic',\n",
       " 'fe_test_0047.mp3': 'folkcountry',\n",
       " 'fe_test_0048.mp3': 'electronic',\n",
       " 'fe_test_0049.mp3': 'electronic',\n",
       " 'fe_test_0050.mp3': 'folkcountry',\n",
       " 'fe_test_0051.mp3': 'electronic',\n",
       " 'fe_test_0052.mp3': 'electronic',\n",
       " 'fe_test_0053.mp3': 'folkcountry',\n",
       " 'fe_test_0054.mp3': 'rock',\n",
       " 'fe_test_0055.mp3': 'electronic',\n",
       " 'fe_test_0056.mp3': 'rock',\n",
       " 'fe_test_0057.mp3': 'raphiphop',\n",
       " 'fe_test_0058.mp3': 'electronic',\n",
       " 'fe_test_0059.mp3': 'folkcountry',\n",
       " 'fe_test_0060.mp3': 'raphiphop',\n",
       " 'fe_test_0061.mp3': 'folkcountry',\n",
       " 'fe_test_0062.mp3': 'electronic',\n",
       " 'fe_test_0063.mp3': 'folkcountry',\n",
       " 'fe_test_0064.mp3': 'raphiphop',\n",
       " 'fe_test_0065.mp3': 'folkcountry',\n",
       " 'fe_test_0066.mp3': 'raphiphop',\n",
       " 'fe_test_0067.mp3': 'electronic',\n",
       " 'fe_test_0068.mp3': 'raphiphop',\n",
       " 'fe_test_0069.mp3': 'folkcountry',\n",
       " 'fe_test_0070.mp3': 'folkcountry',\n",
       " 'fe_test_0071.mp3': 'electronic',\n",
       " 'fe_test_0072.mp3': 'folkcountry',\n",
       " 'fe_test_0073.mp3': 'electronic',\n",
       " 'fe_test_0074.mp3': 'raphiphop',\n",
       " 'fe_test_0075.mp3': 'raphiphop',\n",
       " 'fe_test_0076.mp3': 'electronic',\n",
       " 'fe_test_0077.mp3': 'electronic',\n",
       " 'fe_test_0078.mp3': 'raphiphop',\n",
       " 'fe_test_0079.mp3': 'folkcountry',\n",
       " 'fe_test_0080.mp3': 'electronic',\n",
       " 'fe_test_0081.mp3': 'folkcountry',\n",
       " 'fe_test_0082.mp3': 'raphiphop',\n",
       " 'fe_test_0083.mp3': 'raphiphop',\n",
       " 'fe_test_0084.mp3': 'raphiphop',\n",
       " 'fe_test_0085.mp3': 'folkcountry',\n",
       " 'fe_test_0086.mp3': 'electronic',\n",
       " 'fe_test_0087.mp3': 'raphiphop',\n",
       " 'fe_test_0088.mp3': 'raphiphop',\n",
       " 'fe_test_0089.mp3': 'folkcountry',\n",
       " 'fe_test_0090.mp3': 'raphiphop',\n",
       " 'fe_test_0091.mp3': 'raphiphop',\n",
       " 'fe_test_0092.mp3': 'electronic',\n",
       " 'fe_test_0093.mp3': 'raphiphop',\n",
       " 'fe_test_0094.mp3': 'raphiphop',\n",
       " 'fe_test_0095.mp3': 'raphiphop',\n",
       " 'fe_test_0096.mp3': 'raphiphop',\n",
       " 'fe_test_0097.mp3': 'electronic',\n",
       " 'fe_test_0098.mp3': 'raphiphop',\n",
       " 'fe_test_0099.mp3': 'raphiphop',\n",
       " 'fe_test_0100.mp3': 'electronic',\n",
       " 'fe_test_0101.mp3': 'electronic',\n",
       " 'fe_test_0102.mp3': 'electronic',\n",
       " 'fe_test_0103.mp3': 'raphiphop',\n",
       " 'fe_test_0104.mp3': 'electronic',\n",
       " 'fe_test_0105.mp3': 'electronic',\n",
       " 'fe_test_0106.mp3': 'raphiphop',\n",
       " 'fe_test_0107.mp3': 'electronic',\n",
       " 'fe_test_0108.mp3': 'raphiphop',\n",
       " 'fe_test_0109.mp3': 'electronic',\n",
       " 'fe_test_0110.mp3': 'raphiphop',\n",
       " 'fe_test_0111.mp3': 'raphiphop',\n",
       " 'fe_test_0112.mp3': 'raphiphop',\n",
       " 'fe_test_0113.mp3': 'electronic',\n",
       " 'fe_test_0114.mp3': 'raphiphop',\n",
       " 'fe_test_0115.mp3': 'electronic',\n",
       " 'fe_test_0116.mp3': 'raphiphop',\n",
       " 'fe_test_0117.mp3': 'electronic',\n",
       " 'fe_test_0118.mp3': 'folkcountry',\n",
       " 'fe_test_0119.mp3': 'raphiphop',\n",
       " 'fe_test_0120.mp3': 'raphiphop',\n",
       " 'fe_test_0121.mp3': 'raphiphop',\n",
       " 'fe_test_0122.mp3': 'raphiphop',\n",
       " 'fe_test_0123.mp3': 'raphiphop',\n",
       " 'fe_test_0124.mp3': 'raphiphop',\n",
       " 'fe_test_0125.mp3': 'raphiphop',\n",
       " 'fe_test_0126.mp3': 'electronic',\n",
       " 'fe_test_0127.mp3': 'folkcountry',\n",
       " 'fe_test_0128.mp3': 'raphiphop',\n",
       " 'fe_test_0129.mp3': 'electronic',\n",
       " 'fe_test_0130.mp3': 'electronic',\n",
       " 'fe_test_0131.mp3': 'folkcountry',\n",
       " 'fe_test_0132.mp3': 'raphiphop',\n",
       " 'fe_test_0133.mp3': 'folkcountry',\n",
       " 'fe_test_0134.mp3': 'electronic',\n",
       " 'fe_test_0135.mp3': 'raphiphop',\n",
       " 'fe_test_0136.mp3': 'raphiphop',\n",
       " 'fe_test_0137.mp3': 'raphiphop',\n",
       " 'fe_test_0138.mp3': 'raphiphop',\n",
       " 'fe_test_0139.mp3': 'electronic',\n",
       " 'fe_test_0140.mp3': 'raphiphop',\n",
       " 'fe_test_0141.mp3': 'electronic',\n",
       " 'fe_test_0142.mp3': 'electronic',\n",
       " 'fe_test_0143.mp3': 'electronic',\n",
       " 'fe_test_0144.mp3': 'raphiphop',\n",
       " 'fe_test_0145.mp3': 'raphiphop'}"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# raw_features_predictions()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "All songs are sampled at 44100 Hz.\n",
    "\n",
    "The simplest features that can be extracted from a music time series are the [zero crossing rate](https://en.wikipedia.org/wiki/Zero-crossing_rate) and the [root mean square energy](https://en.wikipedia.org/wiki/Root_mean_square).\n",
    "\n",
    "1. Build a function or a transformer that calculates these two features starting from a raw file input.  In order to go from a music file of arbitrary length to a fixed set of features you will need to use a sliding window approach, which implies making the following choices:\n",
    "\n",
    " 1. what window size are you going to use?\n",
    " 2. what's the overlap between windows?\n",
    "\n",
    " Besides that, you will need to decide how you are going to summarize the values of such features for the whole song. Several strategies are possible:\n",
    " -  you could decide to describe their statistics over the whole song by using descriptors like mean, std and higher order moments\n",
    " -  you could decide to split the song in sections, calculate statistical descriptors for each section and then average them\n",
    " -  you could decide to look at the rate of change of features from one window to the next (deltas).\n",
    " -  you could use any combination of the above.\n",
    "\n",
    " Your goal is to build a transformer that will output a \"song fingerprint\" feature vector that is based on the 2 raw features mentioned above. This vector has to have the same size, regardless of the duration of the song clip it receives.\n",
    "\n",
    "2. Train an estimator that receives the features extracted by the transformer and predicts the genre of a song.  Your solution to Question 1 should be a good starting point.\n",
    "\n",
    "Use this pipeline to predict the genres for the 145 files in the `music_feature_extraction_test.tar.gz` set and submit your predictions as a dictionary.\n",
    "\n",
    "*Hints*\n",
    "- Extracting features from time series can be computationally intensive. Make sure you choose wisely which features to calculate.\n",
    "- You can use MRJob or PySpark to distribute the feature extraction part of your model and then train an estimator on the extracted features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def raw_features_predictions():\n",
    "    return {(\"fe_test_%04d.mp3\" % i): dict2_genre[test_labels[i-1]] for i in xrange(1, 146)}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================\n",
      "Your score:  0.952380952426\n",
      "==================\n"
     ]
    }
   ],
   "source": [
    "# def raw_features_predictions():\n",
    "# #     return {(\"fe_test_%04d.mp3\" % i): 'blues' for i in xrange(1, 146)}\n",
    "#     return {(\"fe_test_%04d.mp3\" % i): dict_genre[test_labels[i-1]] for i in xrange(1, 146)}\n",
    "\n",
    "# grader.score('music__raw_features_predictions', raw_features_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Question 3: All Features Predictions\n",
    "The approach of Question 2 can be generalized to any number and kind of features extracted from a sliding window. Use the [librosa library](https://github.com/librosa/librosa) to extract features that could better represent the genre content of a musical piece.\n",
    "You could use:\n",
    "- spectral features to capture the kind of instruments contained in the piece\n",
    "- MFCCs to capture the variations in frequencies along the piece\n",
    "- Temporal features like tempo and autocorrelation to capture the rhythmic information of the piece\n",
    "- features based on psychoacoustic scales that emphasize certain frequency bands.\n",
    "- any combination of the above\n",
    "\n",
    "As for question 1, you'll need to summarize the time series containing the features using some sort of aggregation. This could be as simple as statistical descriptors or more involved, your choice.\n",
    "\n",
    "As a general rule, build your model gradually. Choose few features that seem interesting, calculate the descriptors and generate predictions.\n",
    "\n",
    "Make sure you `GridSearchCV` the estimators to find the best combination of parameters.\n",
    "\n",
    "Use this pipeline to predict the genres for the 145 files in the `music_feature_extraction_test.tar.gz` set and submit your predictions as a dictionary.\n",
    "\n",
    "**Questions for Consideration:**\n",
    "1. Does your transformer make any assumption on the time duration of the music piece? If so how could that affect your predictions if you receive longer/shorter pieces?\n",
    "\n",
    "2. This model works very well on one of the classes. Which one? Why do you think that is?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "a = 1\n",
    "b = 2\n",
    "c = 3\n",
    "ll = a,b,c\n",
    "st = []\n",
    "st.append(ll)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "st.extend(i for i in range(1,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, 2, 3), 1, 2, 3, 4, 5, 6, 7, 8, 9]"
      ]
     },
     "execution_count": 325,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "st"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def all_feature_eng(t):\n",
    "    rmse_list_s=[]\n",
    "    zcr_list_s=[]\n",
    "    tempo_list_s=[]\n",
    "    mfcc_list_s=[]\n",
    "    delta_mfcc_list_s=[]\n",
    "    beat_list_s=[]\n",
    "\n",
    "    rmse_list_m=[]\n",
    "    zcr_list_m=[]\n",
    "    tempo_list_m=[]\n",
    "    mfcc_list_m=[]\n",
    "    delta_mfcc_list_m=[]\n",
    "    beat_list_m=[]\n",
    "    \n",
    "    mfcc_l = []\n",
    "\n",
    "    features_list = []\n",
    "    \n",
    "    for f in t.getnames():\n",
    "        mono, fs = librosa.load(f, sr = None)\n",
    "        zcr = librosa.feature.zero_crossing_rate(mono)\n",
    "        rmse = librosa.feature.rmse(mono)\n",
    "        tempo, beat = librosa.beat.beat_track(mono,hop_length=256)\n",
    "        mfcc = librosa.feature.mfcc(mono,sr=44100)\n",
    "        delta_mfcc = librosa.feature.delta(mfcc)\n",
    "#         delta = librosa.feature.delta(mono)\n",
    "        \n",
    "#         l = [np.mean(item) for item in mfcc]\n",
    "#         sd_mfcc = [np.std(item) for item in mfcc]\n",
    "\n",
    "        rmse_m = np.mean(rmse)\n",
    "        zcr_m = np.mean(zcr)\n",
    "        tempo_m=np.mean(tempo)\n",
    "        mfcc_m=np.mean(mfcc)\n",
    "        delta_mfcc_m=np.mean(delta_mfcc)\n",
    "#         delta_mfcc_m=delta_mfcc.mean(axis=1)\n",
    "        beat_m = np.mean(beat)\n",
    "        \n",
    "        features = []\n",
    "        features.append(rmse_m)\n",
    "        features.append(zcr_m)\n",
    "        features.append(tempo_m)\n",
    "        features.append(beat_m)\n",
    "        \n",
    "        for i in range(0,len(mfcc)):\n",
    "            features.append(np.mean(mfcc[i]))\n",
    "    \n",
    "        for i in range(0,len(delta_mfcc)):\n",
    "            features.append(np.mean(delta_mfcc[i]))\n",
    "    \n",
    "        \n",
    "        rmse_s = np.std(rmse)\n",
    "        zcr_s = np.std(zcr)\n",
    "        tempo_s=np.std(tempo)\n",
    "        mfcc_s=np.std(mfcc)\n",
    "        delta_mfcc_s=np.std(delta_mfcc)\n",
    "        beat_s=np.std(beat)\n",
    "\n",
    "        features.append(rmse_s)\n",
    "        features.append(zcr_s)\n",
    "        features.append(tempo_s)\n",
    "        features.append(beat_s)\n",
    "        \n",
    "        for i in range(0,len(mfcc)):\n",
    "            features.append(np.std(mfcc[i]))\n",
    "    \n",
    "        for i in range(0,len(delta_mfcc)):\n",
    "            features.append(np.std(delta_mfcc[i]))\n",
    "\n",
    "#         features = rmse_m, rmse_s, zcr_m, zcr_s, tempo_m, tempo_s, beat_m, beat_s,delta_mfcc_m, delta_mfcc_s \n",
    "        \n",
    "        features_list.append(features)  \n",
    "\n",
    "\n",
    "#         mfcc_l.append(l)\n",
    "        \n",
    "#         rmse_list_m.append(rmse_m)\n",
    "#         zcr_list_m.append(zcr_m)\n",
    "#         tempo_list_m.append(tempo_m)\n",
    "#         mfcc_list_m.append(mfcc_m)\n",
    "#         delta_mfcc_list_m.append(delta_mfcc_m)\n",
    "#         beat_list_m.append(beat_m)\n",
    "\n",
    "\n",
    "#         rmse_list_s.append(rmse_s)\n",
    "#         zcr_list_s.append(zcr_s)\n",
    "#         tempo_list_s.append(tempo_s)\n",
    "#         mfcc_list_s.append(mfcc_s)\n",
    "#         delta_mfcc_list_s.append(delta_mfcc_s)\n",
    "#         beat_list_s.append(beat_s)\n",
    "        \n",
    "        \n",
    "\n",
    "\n",
    "# #     features_pd = pd.DataFrame(\n",
    "# #         {'RMSE_M': rmse_list_m,\n",
    "# #          'ZCR_M': zcr_list_m,\n",
    "# #          'RMSE_S': rmse_list_s,\n",
    "# #          'ZCR_S': zcr_list_s,\n",
    "# #          'TEMPO_M': tempo_list_m,\n",
    "# #          'TEMPO_S': tempo_list_s,\n",
    "# #          'MFCC_M': mfcc_list_m,\n",
    "# #          'MFCC_S': mfcc_list_s,\n",
    "# #          'DELTA_M': delta_mfcc_list_m,\n",
    "# #          'DELTA_S': delta_mfcc_list_s,\n",
    "# #          'BEAT_M': beat_list_m,\n",
    "# #          'BEAT_S': beat_list_s,\n",
    "#          'MFCC__%d' % i: value for (i, value) in enumerate(mfcc_l)\n",
    "        #          'MFCCmfcc_l[0],\n",
    "#          'MFCC1': mfcc_l[1],\n",
    "#          'MFCC2': mfcc_l[2],\n",
    "#          'MFCC3': mfcc_l[3],\n",
    "#          'MFCC4': mfcc_l[4],\n",
    "#          'MFCC5': mfcc_l[5],\n",
    "#          'MFCC6': mfcc_l[6],\n",
    "#          'MFCC7': mfcc_l[7],\n",
    "#          'MFCC8': mfcc_l[8],\n",
    "#          'MFCC9': mfcc_l[9],\n",
    "#          'MFCC10': mfcc_l[10],\n",
    "#          'MFCC11': mfcc_l[11],\n",
    "#          'MFCC12': mfcc_l[12],\n",
    "#          'MFCC13': mfcc_l[13],\n",
    "#          'MFCC14': mfcc_l[14],\n",
    "#          'MFCC15': mfcc_l[15],\n",
    "#          'MFCC16': mfcc_l[16],\n",
    "#          'MFCC17': mfcc_l[17],\n",
    "#          'MFCC18': mfcc_l[18]\n",
    "#          'MFCC19': mfcc_l[19],\n",
    "#          })\n",
    "    return features_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#         {'MFCC__%d' % i: value for (i, value) in enumerate(mfcc_l),\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "df_train = all_feature_eng(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1167"
      ]
     },
     "execution_count": 373,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BEAT_M                                               740.312\n",
       "BEAT_S                                               474.105\n",
       "DELTA_M    [-0.0355509506339, -0.0375985567771, 0.0183213...\n",
       "DELTA_S                                               2.4488\n",
       "MFCC_M                                              -2.30404\n",
       "MFCC_S                                               57.0175\n",
       "RMSE_M                                           (0.104415,)\n",
       "RMSE_S                                             0.0421236\n",
       "TEMPO_M                                               49.692\n",
       "TEMPO_S                                                    0\n",
       "ZCR_M                                     (0.0650754442402,)\n",
       "ZCR_S                                              0.0282038\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 308,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.loc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "setting an array element with a sequence.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-367-25db21733a14>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mclf_q3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRandomForestClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmin_samples_leaf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mclf_q3\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf_labels_fac\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/conda/lib/python2.7/site-packages/sklearn/ensemble/forest.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    245\u001b[0m         \"\"\"\n\u001b[1;32m    246\u001b[0m         \u001b[0;31m# Validate or convert input data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 247\u001b[0;31m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"csc\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mDTYPE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    248\u001b[0m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'csc'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mensure_2d\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0missparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python2.7/site-packages/sklearn/utils/validation.pyc\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    380\u001b[0m                                       force_all_finite)\n\u001b[1;32m    381\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 382\u001b[0;31m         \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    383\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mensure_2d\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: setting an array element with a sequence."
     ]
    }
   ],
   "source": [
    "clf_q3 = RandomForestClassifier(min_samples_leaf=20)\n",
    "clf_q3.fit(df_train, df_labels_fac)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "df_test=all_feature_eng(t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "test_labels_q3 = clf_q3.predict(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "145"
      ]
     },
     "execution_count": 379,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import RidgeClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "ridge = RidgeClassifier(alpha=0.2,normalize=True,class_weight='balanced',fit_intercept=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "print(len(df_train))\n",
    "print(len(df_labels_fac))\n",
    "print(len(df_train[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RidgeClassifier(alpha=0.2, class_weight='balanced', copy_X=True,\n",
       "        fit_intercept=True, max_iter=None, normalize=True,\n",
       "        random_state=None, solver='auto', tol=0.001)"
      ]
     },
     "execution_count": 375,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ridge.fit(df_train, df_labels_fac)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1167, 12)"
      ]
     },
     "execution_count": 251,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "test_labels_ridgeclf = ridge.predict(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "145"
      ]
     },
     "execution_count": 381,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_labels_ridge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================\n",
      "Your score:  0.982608695622\n",
      "==================\n"
     ]
    }
   ],
   "source": [
    "def all_features_predictions():\n",
    "#     return {(\"fe_test_%04d.mp3\" % i): 'blues' for i in xrange(1, 146)}\n",
    "    return {(\"fe_test_%04d.mp3\" % i): dict2_genre[test_labels_ridgeclf[i-1]] for i in xrange(1, 146)}\n",
    "\n",
    "\n",
    "# grader.score('music__all_features_predictions', all_features_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "*Copyright &copy; 2016 The Data Incubator.  All rights reserved.*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
